\documentclass{article}
\usepackage{amsmath} %This allows me to use the align functionality.
                     %If you find yourself trying to replicate
                     %something you found online, ensure you're
                     %loading the necessary packages!
\usepackage{amsfonts}%Math font
\usepackage{graphicx}%For including graphics
\usepackage{hyperref}%For Hyperlinks
\usepackage[shortlabels]{enumitem}% For enumerated lists with labels specified
                                  % We had to run tlmgr_install("enumitem") in R
\hypersetup{colorlinks = true,citecolor=black} %set citations to have black (not green) color
\usepackage{natbib}        %For the bibliography
\setlength{\bibsep}{0pt plus 0.3ex}
\bibliographystyle{apalike}%For the bibliography
\usepackage[margin=0.50in]{geometry}
\usepackage{float}
\usepackage{multicol}

%fix for figures
\usepackage{caption}
\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
\begin{document}

\vspace{-1in}
\title{Lab 8 -- MATH 240 -- Computational Statistics}

\author{
  Avery Johnson \\
  Colgate University  \\
  Department of Mathematics  \\
  {\tt aqjohnson@colgate.edu}
}

\date{}

\maketitle

\begin{multicols}{2}
\begin{abstract}
The Beta distribution is a flexible probability distribution on $[0,1]$, commonly used for modeling proportions and probabilities. This lab examines how graphical and numerical summaries of Beta-distributed samples connect to the underlying population distribution, particularly as sample size increases. Two estimation methods, the Method of Moments (MOM) and Maximum Likelihood Estimation (MLE), are compared using death rate data. Results show that MLE provides more precise estimates for $\alpha$, demonstrating a slight advantage over MOM, although both yield similar results. 

\end{abstract}

\noindent \textbf{Keywords:} 
Beta distribution, moments, mean, variance, skewness, kurtosis, MOM estimator, MLE estimator.

\section{Introduction}
The Beta distribution is a continuous probability distribution defined on $[0,1]$, commonly used to model proportions, probabilities, and rates. Controlled by two parameters, $\alpha$ and $\beta$, its shape ranges from highly symmetric to highly skewed, making it flexible for various statistical applications. This lab investigates the properties of the Beta distribution, compares population and sample-based estimates, and applies parameter estimation techniques to real-world data. Additionally, the effectiveness of MOM and MLE in estimating $\alpha$ and $\beta$ is assessed through simulation.

\section{Density Functions and Parameters}
The probability density function (PDF) of a beta distribution is given by:
$$
f_X(x \mid \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma \alpha \Gamma \beta} x^{\alpha-1} (1-x)^{\beta - 1} I(x \in [0,1])
$$
where $I(x \in [0,1]) = 1$ when $x \in [0, 1]$ and $0$ otherwise.

To visualize the impact of the parameters $\alpha$ and $\beta$ on the distribution, four cases were examined: \texttt{Beta(2,5)}, \texttt{Beta(5,5)}, \texttt{Beta(5,2)}, and \texttt{Beta(0.5,0.5)}. The first distribution is right-skewed, the second is symmetric, the third is left-skewed, and the forth is U-shaped. The plots in Figure \ref{populationfigures} demonstrate this, illustrating that increasing $\alpha$ shifts the distribution towards 1, while increasing $\beta$ shifts it towards zero. When $\alpha= \beta$, the distribution is symmetric.

\section{Properties}
Several important properties of the Beta distribution include the mean, variance, skewness, and excess kurtosis. These values were calculated for each Beta distribution using established mathematical formulas (Table \ref{populationsummary}). To verify accuracy, numerical integration was performed to compute moments directly from the PDF using a custom function, \texttt{beta.moment()}, which calculated both the centered and uncentered moments. The results aligned with theoretical expectations.

Random samples of size $n=500$ were generated from each Beta distribution. Histograms were plotted alongside the true PDFs in Figure \ref{samplehistograms}, and numerical summaries were computed (Table \ref{samplestatistics}). Comparing Table \ref{samplestatistics} with Table \ref{populationsummary}, along with analyzing Figure \ref{samplehistograms}, confirms that sample estimates closely approximate theoretical values.

To analyze sample size effects, cumulative statistics were plotted for the \texttt{Beta(2,5)} distribution using the \texttt{cumstats} package in \texttt{R} \citep{cumstats}. A single sample was first examined, followed by a simulation using a \texttt{for()} loop to generate data sets of size 500, adding new cumulative statistics lines at each iteration. The results (Figure \ref{cumstats} in the Appendix) show that variability is high for small samples but decreases as $n$ increases, illustrating convergence to population values. Results indicate the importance of sample size.

<<echo=FALSE, eval=TRUE, results="asis", message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Lab 7 Code
# Avery Johnson
################################################################################

library(tidyverse)

################################################################################
# Task 1: Describe the Population Distribution
################################################################################


population.distribution <- function(alpha, beta) {
  beta.dist <- data.frame(
    alpha = alpha,
    beta = beta,
    mean = alpha / (alpha + beta),
    var = (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1)),
    skew = (2 * (beta - alpha) * sqrt(alpha + beta + 1)) / 
      ((alpha + beta + 2) * sqrt(alpha * beta)),
    kurtosis = (6*((alpha-beta)^2*(alpha+beta+1)-alpha*beta*(alpha+beta+2))) /
      (alpha*beta*(alpha+beta+2)*(alpha+beta+3))
  )
  return(beta.dist)
}

population.table <- bind_rows(
  population.distribution(2,5),
  population.distribution(5,5),
  population.distribution(5,2),
  population.distribution(0.50, 0.50)
)

# create Latex table
library(xtable)
latex_table <- xtable(population.table, 
                      caption="Population-Level Summary",
                      label="populationsummary")

################################################################################
# Task 3: Do Data Summaries Help?
################################################################################

# for beta(2,5) dist
library(e1071)

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 2
beta <- 5
beta.sample1 <- rbeta(n = sample.size,  # sample size
                     shape1 = alpha,   # alpha parameter
                     shape2 = beta)    # beta parameter

beta.sample1 <- tibble(beta.sample1)

sample.stats1 <- beta.sample1 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample1),
    var = var(beta.sample1),
    skew = e1071::skewness(beta.sample1),
    kurtosis = e1071::kurtosis(beta.sample1)
  )

# for beta(5,5) dist

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 5
beta <- 5
beta.sample2 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

beta.sample2 <- tibble(beta.sample2)

sample.stats2 <- beta.sample2 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample2),
    var = var(beta.sample2),
    skew = e1071::skewness(beta.sample2),
    kurtosis = e1071::kurtosis(beta.sample2)
  )

# for beta (5,2) distribution

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 5
beta <- 2
beta.sample3 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

beta.sample3 <- tibble(beta.sample3)

sample.stats3 <- beta.sample3 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample3),
    var = var(beta.sample3),
    skew = e1071::skewness(beta.sample3),
    kurtosis = e1071::kurtosis(beta.sample3)
  )

# for beta(0.5, 0.5 dist)

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 0.5
beta <- 0.5
beta.sample4 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

beta.sample4 <- tibble(beta.sample4)

sample.stats4 <- beta.sample4 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample4),
    var = var(beta.sample4),
    skew = e1071::skewness(beta.sample4),
    kurtosis = e1071::kurtosis(beta.sample4)
  )

sample.stats <- bind_rows(
  sample.stats1,
  sample.stats2,
  sample.stats3,
  sample.stats4
)

# create Latex table
library(xtable)
sample.stats.xtable <- xtable(sample.stats, 
                      caption="Sample Summary",
                      label="samplestatistics")

@

<<echo=FALSE, eval=TRUE, results="asis">>=
# placement="H" places table [H]ere, just like plot
# include.rownames=FALSE doesn’t print the row numbers in this example
print(latex_table,
table.placement = "H", include.rownames=FALSE, size = "small")
@

<<echo=FALSE, eval=TRUE, results="asis">>=
# placement="H" places table [H]ere, just like plot
# include.rownames=FALSE doesn’t print the row numbers in this example
print(sample.stats.xtable,
table.placement = "H", include.rownames=FALSE, size = "small")
@

\pagebreak
\section{Estimators}
Since the true value of $\alpha$ and $\beta$ are unknown in real-world applications, parameter estimation methods are essential. Two widely used techniques are the Method of Moments (MOM) and Maximum Likelihood Estimation (MLE). MOM estimates parameters by equating sample moments to their corresponding population moments. Using the \texttt{nleqslv} package in \texttt{R}, parameters were chosen to match sample and population moments. MLE is a more general and widely used technique for parameter estimation. It finds the values of $\alpha$ and $\beta$ that maximize the likelihood of the observed data. The likelihood function is a product of the Beta PDF evaluated at each data point, but computationally, it is easier to work with the log-likelihood function. The \texttt{optim()} function in \texttt{R} was used to maximize the log-likelihood. MLE is generally regarded as more efficient since it often provides more precise estimates.

\section{Death Rates Example}
The flexibility of the Beta distribution was tested by modeling real-world death rate data from the world bank \citep{deathrates}. The data, representing deaths per 1,000 citizens, was transformed into a rate and fitted to a Beta distribution using both MOM and MLE. Parameter estimates were obtained by solving moment equations for MOM and optimizing the likelihood function for MLE (Table \ref{momandmle}). While the estimates for $\alpha$ weere similar across methods, the estimates for $\beta$ differed slightly.

<<echo=FALSE, eval=TRUE, results="asis", message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Task 6: Collect and Clean Data
################################################################################
library(tidyverse)
death.rates <- read_csv("countrydeathrates.csv", skip=3)

death.data <- death.rates |>
  select("Country Name", "Country Code", `2022`) |> #keep only relevant columns
  filter(!is.na(`2022`)) |>
  mutate(`2022` = `2022` / 1000) |> #convert to rate
  rename("death rate" = `2022` )

################################################################################
# Task 7: What are alpha and beta?
################################################################################
library(nleqslv)

# MOM
MOM.beta <- function(data, par){
  alpha <- par[1]
  beta <- par[2]
  
  EX <- alpha / (alpha + beta)
  EX2 <- ((alpha + 1) * alpha) / ((alpha + beta + 1)*(alpha + beta))
  m1 <- mean(data)
  m2 <- mean(data^2)
  
  return(c((EX-m1), (EX2-m2))) # goal: find alpha and beta so these are 0
}

mom.estimates <- nleqslv(x = c(1, 1), # guess
        fn = MOM.beta,
        data=death.data$`death rate`)

mom.alpha <- mom.estimates$x[1]
mom.beta <- mom.estimates$x[2]

# MLE
llbeta <- function(data, par, neg=FALSE){
  alpha <- par[1]
  beta <- par[2]
  loglik <- sum(log(dbeta(x=data, alpha, beta)))
  
  return(ifelse(neg, -loglik, loglik))
}

mle.estimates <- optim(par = c(1,1),
      fn = llbeta,
      data=death.data$`death rate`,
      neg = T)

mle.alpha <- mle.estimates$par[1]
mle.beta <- mle.estimates$par[2]

estimates <- data.frame(
  Method = c("MOM", "MLE"),
  Alpha = c(mom.alpha, mle.alpha),
  Beta = c(mom.beta, mle.beta)
)

momandmle <- xtable(estimates,
                    caption="MOM and MLE Estimates",
                    label="momandmle")

@
<<echo=FALSE, eval=TRUE, results="asis">>=
# placement="H" places table [H]ere, just like plot
# include.rownames=FALSE doesn’t print the row numbers in this example
print(momandmle,
table.placement = "H", include.rownames=FALSE, size = "small")
@

To visualize the results, histograms of the empirical data were plotted with the estimated Beta distributions superimposed (Figure \ref{estimatedhistogram}). Both methods produced reasonable fits. To determine which estimators we should use, then, we computed bias, precision, and mean squared error (Table \ref{biasprecision}). Density plots (Figure \ref{densitycomparison}) further helped us visualize estimator differences. The results indicate that while MLE provided more narrow (precise) estimates for $\alpha$, both methods performed similarly overall.

\section{Conclusion}
This study illustrates the flexibility of the Beta distirbution and its usefulness in modeling proportion-based data. Graphical and numerical summaries show that sample estimates converge to population values as sample size increases. Additionally, the comparison of MOM and MLE estimators reveals that while both methods yield accurate and comparable results, MLE generally provides more precise parameter estimates. These findings reinforce the importance of selecting appropriate estimation techniques depending on the application and data characteristics.

\columnbreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{2em}

\begin{tiny}
\bibliography{bib}
\end{tiny}


\end{multicols}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\onecolumn
\section{Appendix}

\subsection{Density Function and Parameters}
\subsubsection{Population Distribution Figures}
<<plot1, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
# plot these four distributions 
fig.1.data <- tibble(x = seq(-0.25, 1.25, length.out=1000))|>   # generate a grid of points
  mutate(beta.pdf = dbeta(x, 2, 5))                          # compute the beta PDF

plot1 <- ggplot(data= fig.1.data)+                                           # specify data
  geom_line(aes(x=x, y=beta.pdf, color="Beta(2,5)")) +          # plot beta dist
  geom_hline(yintercept=0)+                                            # plot x axis
  theme_bw()+                                                          # change theme
  xlab("x")+                                                           # label x axis
  ylab("Density")+                                                     # label y axis
  scale_color_manual("", values = c("black", "grey"))+                 # change colors
  theme(legend.position = "bottom")                                    # move legend to bottom


fig.2.data <- tibble(x = seq(-0.25, 1.25, length.out=1000))|>   
  mutate(beta.pdf = dbeta(x, 5, 5))                          
         
plot2 <- ggplot(data= fig.2.data)+                                          
  geom_line(aes(x=x, y=beta.pdf, color="Beta(5,5)")) +          
  geom_hline(yintercept=0)+                                            
  theme_bw()+                                                          
  xlab("x")+                                                          
  ylab("Density")+                                                     
  scale_color_manual("", values = c("black", "grey"))+                
  theme(legend.position = "bottom")

fig.3.data <- tibble(x = seq(-0.25, 1.25, length.out=1000))|>   
  mutate(beta.pdf = dbeta(x, 5, 2))                          

plot3 <- ggplot(data= fig.3.data)+                                          
  geom_line(aes(x=x, y=beta.pdf, color="Beta(5,2)")) +          
  geom_hline(yintercept=0)+                                            
  theme_bw()+                                                          
  xlab("x")+                                                          
  ylab("Density")+                                                     
  scale_color_manual("", values = c("black", "grey"))+                
  theme(legend.position = "bottom") 

fig.4.data <- tibble(x = seq(-0.25, 1.25, length.out=1000))|>   
  mutate(beta.pdf = dbeta(x, 0.5, 0.5))                          

plot4 <- ggplot(data= fig.4.data)+                                          
  geom_line(aes(x=x, y=beta.pdf, color="Beta(0.5,0.5)")) +          
  geom_hline(yintercept=0)+                                            
  theme_bw()+                                                          
  xlab("x")+                                                          
  ylab("Density")+                                                     
  scale_color_manual("", values = c("black", "grey"))+                
  theme(legend.position = "bottom") 

library(patchwork)
population.figures <- plot1 + plot2 + plot3 + plot4
population.figures
@

\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(2.5,1.75)>>=
@
\caption{Population Figures for Various Beta Distributions}
\label{populationfigures} %we can now reference plot1
\end{center}
\end{figure}

\pagebreak
\subsection{Properties}
\subsubsection{Sample Distribution Figures}
<<plot2, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Task 3: Do Data Summaries Help?
################################################################################

# for beta(2,5) dist
library(e1071)

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 2
beta <- 5
beta.sample1 <- rbeta(n = sample.size,  # sample size
                     shape1 = alpha,   # alpha parameter
                     shape2 = beta)    # beta parameter

beta.sample1 <- tibble(beta.sample1)

sample.stats1 <- beta.sample1 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample1),
    variance = var(beta.sample1),
    skewness = e1071::skewness(beta.sample1),
    excess_kurt = e1071::kurtosis(beta.sample1)
  )

hist1 <- ggplot() +
  geom_histogram(data=beta.sample1,
                 aes(x=beta.sample1, y=after_stat(density)),
                 breaks=seq(0,1,0.1),
                 fill="grey30",
                 color="lightgrey")+
  stat_density(data=beta.sample1,
               aes(x=beta.sample1, color="Density"), geom="line") +
  geom_line(data=fig.1.data,
            aes(x=x, y=beta.pdf, color="Population Beta Dist")) +
  geom_hline(yintercept = 0) +
  theme_bw()+
  xlab("x")+
  ylab("Density") +
  labs(color="Line") +
  ggtitle("Beta (2,5) Distribution")

# for beta(5,5) dist

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 5
beta <- 5
beta.sample2 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

beta.sample2 <- tibble(beta.sample2)

sample.stats2 <- beta.sample2 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample2),
    variance = var(beta.sample2),
    skewness = e1071::skewness(beta.sample2),
    excess_kurt = e1071::kurtosis(beta.sample2)
  )

hist2 <- ggplot() +
  geom_histogram(data=beta.sample2,
                 aes(x=beta.sample2, y=after_stat(density)),
                 breaks=seq(0,1,0.1),
                 fill="grey30",
                 color="lightgrey")+
  stat_density(data=beta.sample2,
               aes(x=beta.sample2, color="Density"), geom="line") +
  geom_line(data=fig.2.data,
            aes(x=x, y=beta.pdf, color="Population Beta Dist")) +
  geom_hline(yintercept = 0) +
  theme_bw()+
  xlab("x")+
  ylab("Density") +
  labs(color="Line") +
  ggtitle("Beta (5,5) Distribution")

# for beta (5,2) distribution

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 5
beta <- 2
beta.sample3 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

beta.sample3 <- tibble(beta.sample3)

sample.stats3 <- beta.sample3 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample3),
    variance = var(beta.sample3),
    skewness = e1071::skewness(beta.sample3),
    excess_kurt = e1071::kurtosis(beta.sample3)
  )

hist3 <- ggplot() +
  geom_histogram(data=beta.sample3,
                 aes(x=beta.sample3, y=after_stat(density)),
                 breaks=seq(0,1,0.1),
                 fill="grey30",
                 color="lightgrey")+
  stat_density(data=beta.sample3,
               aes(x=beta.sample3, color="Density"), geom="line") +
  geom_line(data=fig.3.data,
            aes(x=x, y=beta.pdf, color="Population Beta Dist")) +
  geom_hline(yintercept = 0) +
  theme_bw()+
  xlab("x")+
  ylab("Density") +
  labs(color="Line") +
  ggtitle("Beta (5,2) Distribution")

# for beta(0.5, 0.5 dist)

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 0.5
beta <- 0.5
beta.sample4 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

beta.sample4 <- tibble(beta.sample4)

sample.stats4 <- beta.sample4 |>
  summarize(
    alpha=alpha,
    beta=beta,
    mean = mean(beta.sample4),
    variance = var(beta.sample4),
    skewness = e1071::skewness(beta.sample4),
    excess_kurt = e1071::kurtosis(beta.sample4)
  )

hist4 <- ggplot() +
  geom_histogram(data=beta.sample4,
                 aes(x=beta.sample4, y=after_stat(density)),
                 breaks=seq(0,1,0.1),
                 fill="grey30",
                 color="lightgrey")+
  stat_density(data=beta.sample4,
               aes(x=beta.sample4, color="Density"), geom="line") +
  geom_line(data=fig.4.data,
            aes(x=x, y=beta.pdf, color="Population Beta Dist")) +
  geom_hline(yintercept = 0) +
  theme_bw()+
  xlab("x")+
  ylab("Density") +
  labs(color="Line") +
  ggtitle("Beta (0.5,0.5) Distribution")

sample.histograms <- hist1 + hist2 + hist3 + hist4 + plot_layout(guides = 'collect')

sample.histograms
@

\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(2.5,1.75)>>=
@
\caption{Sample Figures for Various Beta Distributions}
\label{samplehistograms} %we can now reference plot1
\end{center}
\end{figure}

\pagebreak
\subsubsection{Cumulative Statistics: Does Sample Size Matter?}

<<plot3, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Task 4: Is Sample Size Important?
################################################################################

# for the beta(2,5) dist.
library("cumstats")

set.seed(7272) # Set seed so we all get the same results.
sample.size <- 500 # Specify sample details
alpha <- 2
beta <- 5
beta.sample1 <- rbeta(n = sample.size,  # sample size
                      shape1 = alpha,   # alpha parameter
                      shape2 = beta)    # beta parameter

cumstats.data <- data.frame(
  alpha=2,
  beta=5,
  mean = cummean(beta.sample1),
  var = cumvar(beta.sample1),
  skew = cumskew(beta.sample1),
  kurtosis = cumkurt(beta.sample1)
)

cumstats.data <- cumstats.data |>
  mutate(observation = 1:n())

pop.mean <- alpha / (alpha + beta)
pop.var <- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))
pop.skew <- (2 * (beta - alpha) * sqrt(alpha + beta + 1)) / 
  ((alpha + beta + 2) * sqrt(alpha * beta))
pop.kurt <- (6*((alpha-beta)^2*(alpha+beta+1)-alpha*beta*(alpha+beta+2))) /
  (alpha*beta*(alpha+beta+2)*(alpha+beta+3))
  


cumstats.mean <- ggplot(data=cumstats.data) +
  geom_line(aes(x=observation, y=mean, color="Cumulative Mean"), show.legend=F) +
  geom_hline(yintercept=pop.mean)+  
  xlab("observation") +
  ylab("mean") +
  ggtitle("Cumulative Statistics Mean") +
  theme_bw()

cumstats.var <- ggplot(data=cumstats.data) +
  geom_line(aes(x=observation, y=var, color="Cumulative Variance"), show.legend=F) +
  geom_hline(yintercept = pop.var) +  
  xlab("observation") +
  ylab("variance") +
  ggtitle("Cumulative Statistics Variance") +
  theme_bw()

cumstats.skew <- ggplot(data=cumstats.data) +
  geom_line(aes(x=observation, y=skew, color="Cumulative Skewness"), show.legend=F) +
  geom_hline(yintercept = pop.skew) +
  xlab("observation") +
  ylab("skewness") +
  ggtitle("Cumulative Statistics Skewness") +
  theme_bw()

cumstats.kurt <- ggplot(data=cumstats.data) +
  geom_line(aes(x=observation, y=kurtosis-3, color="Cumulative Kurtosis"), show.legend=F) +
  geom_hline(yintercept = pop.kurt) + 
  xlab("observation") +
  ylab("kurtosis") +
  ggtitle("Cumulative Statistics Kurtosis") +
  theme_bw()

library(patchwork)
cumulative.stats <-  cumstats.mean + cumstats.var + cumstats.skew + cumstats.kurt

# now do this in a for loop for 2:50
for (i in 2:50){
  set.seed(7272 + i)
  sample.size <- 500 # Specify sample details
  alpha <- 2
  beta <- 5
  beta.sample <- rbeta(n = sample.size,  # sample size
                        shape1 = alpha,   # alpha parameter
                        shape2 = beta)    # beta parameter
  
  new.cumstats.data <- data.frame(
    alpha=2,
    beta=5,
    mean = cummean(beta.sample),
    var = cumvar(beta.sample),
    skew = cumskew(beta.sample),
    kurtosis = cumkurt(beta.sample)-3
  )
  
  new.cumstats.data <- new.cumstats.data |>
    mutate(observation = 1:n())
  
  cumstats.mean <- cumstats.mean +
    geom_line(data=new.cumstats.data, aes(x=observation, y=mean), color=i)
  
  cumstats.var <- cumstats.var + 
    geom_line(data=new.cumstats.data, aes(x=observation, y=var), color=i)
  
  cumstats.skew <- cumstats.skew +
    geom_line(data=new.cumstats.data, aes(x=observation, y=skew), color=i)
  
  cumstats.kurt <- cumstats.kurt +
    geom_line(data=new.cumstats.data, aes(x=observation, y=kurtosis), color=i)
  
  cumulative.stats.new <- cumstats.mean + cumstats.var + cumstats.skew + cumstats.kurt
  }

cumulative.stats.new

@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(2.5,1.75)>>=
@
\caption{Cumulative Statistics as Sample Size Increases}
\label{cumstats} %we can now reference plot1
\end{center}
\end{figure}

\pagebreak
\subsubsection{Modeling the Variation}
<<plot4, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=

new.stats <- data.frame() 

for (i in 1:1000){
  set.seed(7272 + i)
  sample.size <- 500 # Specify sample details
  alpha <- 2
  beta <- 5
  beta.sample <- rbeta(n = sample.size,  # sample size
                       shape1 = alpha,   # alpha parameter
                       shape2 = beta)    # beta parameter
  stats <- data.frame(
    alpha = alpha,
    beta = beta,
    mean = mean(beta.sample),
    variance = var(beta.sample),
    skewness = e1071::skewness(beta.sample),
    excess_kurt = e1071::kurtosis(beta.sample)
  )
  
  new.stats <- bind_rows(new.stats, stats)
}

view(new.stats)

# Plot Stats

# Mean Plot
mean.plot <- ggplot() +
  geom_histogram(data = new.stats, aes(x=mean, y=after_stat(density)), 
                 bins=40,
                 fill="grey30",
                 color="lightgray")+
  geom_density(data=new.stats, aes(x=mean, color="Density")) +
  theme_bw() +
  ggtitle("Histogram of Means") +
  xlab("Mean") +
  ylab("Density") +
  labs(color="Line")

# Variance Plot
var.plot <- ggplot() +
  geom_histogram(data = new.stats, aes(x=variance, y=after_stat(density)), 
                 bins=40,
                 fill="grey30",
                 color="lightgray")+
  geom_density(data=new.stats, aes(x=variance, color="Density")) +
  theme_bw() +
  ggtitle("Histogram of Variances") +
  xlab("Variance") +
  ylab("Density") +
  labs(color="Line")

# Skew Plot
skew.plot <- ggplot() +
  geom_histogram(data = new.stats, aes(x=skewness, y=after_stat(density)), 
                 bins=40,
                 fill="grey30",
                 color="lightgray")+
  geom_density(data=new.stats, aes(x=skewness, color="Density")) +
  theme_bw() +
  ggtitle("Histogram of Skewnesses") +
  xlab("Skewness") +
  ylab("Density") +
  labs(color="Line")

# Excess Kurt Plot
kurt.plot <- ggplot() +
  geom_histogram(data = new.stats, aes(x=excess_kurt, y=after_stat(density)), 
                 bins=40,
                 fill="grey30",
                 color="lightgray")+
  geom_density(data=new.stats, aes(x=excess_kurt, color="Density")) +
  theme_bw() +
  ggtitle("Histogram of Excess Kurtosis") +
  xlab("Excess Kurtosis") +
  ylab("Density") +
  labs(color="Line")

stats.plots <- mean.plot + var.plot + skew.plot + kurt.plot + plot_layout(guides = "collect")
stats.plots

@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(2.5,1.75)>>=
@
\caption{Modeling the Variation of Statistics}
\label{variation} %we can now reference plot1
\end{center}
\end{figure}

\pagebreak
\subsection{Estimators}
\subsection{Example}
\subsubsection{MOM vs. MLE Estimates}
<<plot5, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Task 6: Collect and Clean Data
################################################################################
library(tidyverse)
death.rates <- read_csv("countrydeathrates.csv", skip=3)

death.data <- death.rates |>
  select("Country Name", "Country Code", `2022`) |> #keep only relevant columns
  filter(!is.na(`2022`)) |>
  mutate(`2022` = `2022` / 1000) |> #convert to rate
  rename("death rate" = `2022` )

################################################################################
# Task 7: What are alpha and beta?
################################################################################
library(nleqslv)

# MOM
MOM.beta <- function(data, par){
  alpha <- par[1]
  beta <- par[2]
  
  EX <- alpha / (alpha + beta)
  EX2 <- ((alpha + 1) * alpha) / ((alpha + beta + 1)*(alpha + beta))
  m1 <- mean(data)
  m2 <- mean(data^2)
  
  return(c((EX-m1), (EX2-m2))) # goal: find alpha and beta so these are 0
}

mom.estimates <- nleqslv(x = c(1, 1), # guess
        fn = MOM.beta,
        data=death.data$`death rate`)

mom.alpha <- mom.estimates$x[1]
mom.beta <- mom.estimates$x[2]

# MLE
llbeta <- function(data, par, neg=FALSE){
  alpha <- par[1]
  beta <- par[2]
  loglik <- sum(log(dbeta(x=data, alpha, beta)))
  
  return(ifelse(neg, -loglik, loglik))
}

mle.estimates <- optim(par = c(1,1),
      fn = llbeta,
      data=death.data$`death rate`,
      neg = T)

mle.alpha <- mle.estimates$par[1]
mle.beta <- mle.estimates$par[2]

estimates <- data.frame(
  Method = c("MOM", "MLE"),
  Alpha = c(mom.alpha, mle.alpha),
  Beta = c(mom.beta, mle.beta)
)

density.data <- tibble(x=seq(0,0.023, length.out=1000)) |>
  mutate(mom.density = dbeta(x, mom.alpha, mom.beta),
         mle.density = dbeta(x, mle.alpha, mle.beta))

# histograms 
death.rates <- ggplot() + 
  geom_histogram(data=death.data,
           aes(x=`death rate`,
               y=after_stat(density)),
           fill="grey")+
  geom_line(data = density.data, aes(x=x, y=mom.density, color="MOM Estimate")) +
  geom_line(data = density.data, aes(x=x, y=mle.density, color="MLE Estimate")) +
  theme_bw() +
  xlab("Death Rate") +
  ylab("Density") +
  ggtitle("Death Rates with Estimated Beta Distributions") 

death.rates
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(2.5,1.75)>>=
@
\caption{Estimated Beta Distributions}
\label{estimatedhistogram} %we can now reference plot1
\end{center}
\end{figure}

\pagebreak

\subsubsection{Bias, Precision, and Mean Squared Error of Estimates}
<<echo=FALSE, eval=TRUE, results="asis", message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Task 8: Which estimators should we use
################################################################################

results <- data.frame(mom.alpha = numeric(1000), 
                      mom.beta = numeric(1000), 
                      mle.alpha = numeric(1000), 
                      mle.beta = numeric(1000))

for (i in 1:1000){
  set.seed(7272 + i)
  sample.size <- 266 # Specify sample details
  alpha <- 8
  beta <- 950
  beta.sample <- rbeta(n = sample.size,  # sample size
                       shape1 = alpha,   # alpha parameter
                       shape2 = beta)    # beta parameter

  # MOM ESTIMATES
  mom.estimates <- nleqslv(x = c(1, 1), # guess
                           fn = MOM.beta,
                           data=beta.sample)
  
  mom.alpha <- mom.estimates$x[1]
  mom.beta <- mom.estimates$x[2]
  
  # MLE ESTIMATES
  mle.estimates <- optim(par = c(1,1),
                         fn = llbeta,
                         data=beta.sample,
                         neg = T)
  
  mle.alpha <- mle.estimates$par[1]
  mle.beta <- mle.estimates$par[2]
  
  results[i, ] <- c(mom.alpha, mom.beta, mle.alpha, mle.beta)
}

# true parameters
alpha_true <- 8
beta_true <- 950

#compute bias, precision, MLE
bias_mom_alpha <- mean(results$mom.alpha) - alpha_true
bias_mom_beta <- mean(results$mom.beta) - beta_true
bias_mle_alpha <- mean(results$mle.alpha) - alpha_true
bias_mle_beta <- mean(results$mle.beta) - beta_true

precision_mom_alpha <- 1 / var(results$mom.alpha)
precision_mom_beta <- 1 / var(results$mom.beta)
precision_mle_alpha <- 1 / var(results$mle.alpha)
precision_mle_beta <- 1 / var(results$mle.beta)

mse_mom_alpha <- var(results$mom.alpha) + bias_mom_alpha^2
mse_mom_beta <- var(results$mom.beta) + bias_mom_beta^2
mse_mle_alpha <- var(results$mle.alpha) + bias_mle_alpha^2
mse_mle_beta <- var(results$mle.beta) + bias_mle_beta^2

summary.table <- data.frame(
  Parameter = c("Alpha", "Beta"),
  Bias_MOM = c(bias_mom_alpha, bias_mom_beta),
  Bias_MLE = c(bias_mle_alpha, bias_mle_beta),
  Precision_MOM = c(precision_mom_alpha, precision_mom_beta),
  Precision_MLE = c(precision_mle_alpha, precision_mle_beta),
  MSE_MOM = c(mse_mom_alpha, mse_mom_beta),
  MSE_MLE = c(mse_mle_alpha, mse_mle_beta)
)

bias.precision <- xtable(summary.table, 
                         caption="Bias, Precision, and Mean Squared Error",
                         label = "biasprecision")
@
<<echo=FALSE, eval=TRUE, results="asis">>=
# placement="H" places table [H]ere, just like plot
# include.rownames=FALSE doesn’t print the row numbers in this example
print(bias.precision,
table.placement = "H", include.rownames=FALSE, size = "small")
@

\pagebreak
\subsubsection{Estimated Density for MOM and MLE}
<<plot6, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Task 8: Which estimators should we use
################################################################################

results <- data.frame(mom.alpha = numeric(1000), 
                      mom.beta = numeric(1000), 
                      mle.alpha = numeric(1000), 
                      mle.beta = numeric(1000))

for (i in 1:1000){
  set.seed(7272 + i)
  sample.size <- 266 # Specify sample details
  alpha <- 8
  beta <- 950
  beta.sample <- rbeta(n = sample.size,  # sample size
                       shape1 = alpha,   # alpha parameter
                       shape2 = beta)    # beta parameter

  # MOM ESTIMATES
  mom.estimates <- nleqslv(x = c(1, 1), # guess
                           fn = MOM.beta,
                           data=beta.sample)
  
  mom.alpha <- mom.estimates$x[1]
  mom.beta <- mom.estimates$x[2]
  
  # MLE ESTIMATES
  mle.estimates <- optim(par = c(1,1),
                         fn = llbeta,
                         data=beta.sample,
                         neg = T)
  
  mle.alpha <- mle.estimates$par[1]
  mle.beta <- mle.estimates$par[2]
  
  results[i, ] <- c(mom.alpha, mom.beta, mle.alpha, mle.beta)
}
view(results)

# true parameters
alpha_true <- 8
beta_true <- 950

#compute bias, precision, MLE
bias_mom_alpha <- mean(results$mom.alpha) - alpha_true
bias_mom_beta <- mean(results$mom.beta) - beta_true
bias_mle_alpha <- mean(results$mle.alpha) - alpha_true
bias_mle_beta <- mean(results$mle.beta) - beta_true

precision_mom_alpha <- 1 / var(results$mom.alpha)
precision_mom_beta <- 1 / var(results$mom.beta)
precision_mle_alpha <- 1 / var(results$mle.alpha)
precision_mle_beta <- 1 / var(results$mle.beta)

mse_mom_alpha <- var(results$mom.alpha) + bias_mom_alpha^2
mse_mom_beta <- var(results$mom.beta) + bias_mom_beta^2
mse_mle_alpha <- var(results$mle.alpha) + bias_mle_alpha^2
mse_mle_beta <- var(results$mle.beta) + bias_mle_beta^2

summary.table <- data.frame(
  Parameter = c("Alpha", "Beta"),
  Bias_MOM = c(bias_mom_alpha, bias_mom_beta),
  Bias_MLE = c(bias_mle_alpha, bias_mle_beta),
  Precision_MOM = c(precision_mom_alpha, precision_mom_beta),
  Precision_MLE = c(precision_mle_alpha, precision_mle_beta),
  MSE_MOM = c(mse_mom_alpha, mse_mom_beta),
  MSE_MLE = c(mse_mle_alpha, mse_mle_beta)
)

view(summary.table)

# create density plots
p1 <- ggplot() +
  geom_density(data=results, aes(x=mom.alpha, color="Density")) +
  ggtitle("MOM Alpha Density") +
  xlab("MOM Density") +
  ylab("Density")

p2<- ggplot() + 
  geom_density(data=results, aes(x=mom.beta, color="Density")) +
  ggtitle("MOM Beta Density") +
  xlab("MOM Density") +
  ylab("Density")

p3 <- ggplot() +
  geom_density(data=results, aes(x=mle.alpha, color="Density")) +
  ggtitle("MLE Alpha Density") +
  xlab("MLE Density") +
  ylab("Density")

p4<- ggplot() + 
  geom_density(data=results, aes(x=mle.beta, color="Density")) +
  ggtitle("MLE Beta Density") +
  xlab("MLE Density") +
  ylab("Density")

plot.grid <- p1 + p2 + p3 + p4

p.alpha <- ggplot() +
  geom_density(data=results, aes(x=mom.alpha, color="MOM")) +
  geom_density(data=results, aes(x=mle.alpha, color="MLE")) +
  theme_bw() +
  ggtitle("Alpha Density") +
  xlab("Alpha") +
  ylab("Density") +
  scale_color_manual(name = "Estimator", values = c("MOM" = "blue", "MLE" = "red"))
  
p.beta <- ggplot() +
  geom_density(data=results, aes(x=mom.beta, color="MOM")) +
  geom_density(data=results, aes(x=mle.beta, color="MLE")) +
  theme_bw() +
  ggtitle("Beta Density") +
  xlab("Beta") +
  ylab("Density") +
  scale_color_manual(name = "Estimator", values = c("MOM" = "blue", "MLE" = "red"))

density.comparison <- p.alpha + p.beta
density.comparison

@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(2.5,1.75)>>=
@
\caption{Estimated Densities for MOM and MLE}
\label{densitycomparison} %we can now reference plot1
\end{center}
\end{figure}

\end{document}